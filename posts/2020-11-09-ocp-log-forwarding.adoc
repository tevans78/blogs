---
layout: post
title: "Forwarding Open Liberty logs in OpenShift Container Platform to Splunk using Log Forwarding API"
categories: blog
author_picture: https://avatars3.githubusercontent.com/melissa-lee
author_github: https://github.com/melissa-lee
seo-title: Forwarding Open Liberty logs in OpenShift to Splunk by using the Log Forwarding API - OpenLiberty.io
seo-description: Using the Log Forwarding API, you can send logs from Open Liberty that are deployed in OpenShift Container Platform to remote destinations. You can deploy Splunk on your external machine or inside your OpenShift Container Platform. The logs can be forwarded to Splunk using the Fluentd forward protocol.
blog_description: Using the Log Forwarding API, you can send logs from Open Liberty deployed in OpenShift Container Platform to remote destinations. You can deploy Splunk on your external machine or inside your OpenShift Container Platform. The logs can be forwarded to Splunk using the Fluentd forward protocol.
additional_authors:
- name: David Chan
  github: https://github.com/Channyboy
  image: https://avatars0.githubusercontent.com/Channyboy
---
= Forwarding Open Liberty logs in OpenShift to Splunk by using the Log Forwarding API
Halim Lee <https://github.com/leemelim>

Collecting logs in a single location helps you monitor all of your applications efficiently, which is especially important in highly distributed and dynamic container orchestration systems. Red Hat OpenShift Container Platform (OpenShift) provides a built-in log aggregation solution that uses Elasticsearch, Fluentd, and Kibana, also known as the EFK stack. In addition to the EFK stack, you can use the https://docs.openshift.com/container-platform/4.6/logging/cluster-logging-external.html#cluster-logging-collector-log-forwarding-about_cluster-logging-external[Log Forwarding API] to send logs from an OpenShift cluster to other log analysis solutions. The Log Forwarding API is available starting with OpenShift 4.6, and in OpenShift 4.3 to 4.5 as a Technology Preview feature.

Splunk is one of the most popular log analysis solutions. If you want to start using Splunk as your logging solution for Open Liberty on OpenShift, you must first integrate OpenShift with Splunk. The Log Forwarding API simplifies OpenShift cluster integration with Splunk. You can configure custom pipelines to send logs to endpoints that are either inside or outside of your OpenShift cluster.

This blog post walks you through configuring the Log Forwarding API on your OpenShift cluster to forward your logs to a Fluentd and Splunk deployment that is external to your cluster.  We also cover the configuration and deployment of the Fluentd and Splunk server on an external machine. The Fluentd server redirects the forwarded logs to Splunk by using Splunk's HTTP Event Collector (HEC) API. In the final sections, you integrate Open Liberty logs with the Fluentd forwarder and setup Splunk dashboards that are provided by the Open Liberty team.

If you would rather set up the Log Forwarding API, Fluentd forwarder, and Splunk locally within your OpenShift cluster, see link:https://www.openshift.com/blog/forwarding-logs-to-splunk-using-the-openshift-log-forwarding-api[Forwarding Logs to Splunk Using the OpenShift Log Forwarding API] on the OpenShift blog. After you complete those steps, proceed to the <<integrating-open-liberty-json-logs,Integrating Open Liberty JSON Logs>> and <<setting-up-splunk-dashboard,Setting Up Splunk-Dashboard>> sections of this blog post to complete your setup.


== Configuring the Log Forwarding API

. Ensure that your cluster logging instance is created and all pods are fully operational. For more information, see the link:https://docs.openshift.com/container-platform/4.6/logging/cluster-logging-deploying.html[Deploying cluster logging] documentation for your OpenShift version. 

. [[keycert-secret]]*(Optional: Security)* It is recommended that you secure your connection between the Fluentd servers on your OpenShift cluster and the external Fluentd server. This step creates a _secret_ that is used by the Log Forwarding API in step 3 to achieve a secure connection. This procedure assumes that the necessary key and certificate files, for example `tls.crt` and `tls.key`, are already created. The instructions for creating the keys and certificates are not within the scope of this blog post. The key and certificate are also used when you <<keycert-fluentd, deploy the external Fluentd server>>.
+
--
.. Switch to the `openshift-logging` project
+
[source]
----
oc project openshift-logging
----
.. Create the secret that contains the key and certificate. You also need to specify a _shared_key_, which is a string password that is used as an extra layer of authentication between the Fluentd servers on the OpenShift cluster and the external Fluentd server. The examples in this blog post use _secure-forward_ for the secret name and  _"secretpassword"_ for the shared key. Change the paths in the following example as necessary:
+
[source]
----
oc create secret generic secure-forward --from-file=ca-bundle.crt=/path/to/tls.crt --from-file=tls.crt=/path/to/tls.crt --from-file=tls.key=/path/to/tls.key   --from-literal=shared_key=secretpassword
----
--

. Create the `log-forward-instance.yaml` file. Configure the outputs and pipelines.
+
--
* Outputs can be either `elasticsearch` or `forward`. The `elasticsearch` output routes logs to an internal or external Elasticsearch cluster. The `forward` output forwards logs to an external log aggregation solution through the Fluentd forward protocols.
* Pipelines can be  `logs.app`, `logs.infra`, or `logs.audit`. For more information, see link:https://docs.openshift.com/container-platform/4.6/logging/cluster-logging-external.html#cluster-logging-collector-log-forward-about_cluster-logging-external[Understanding the Log Forwarding API].
* If you are using a *secured* connection, specify the name of the secret that you created in step 2:
+
```
   - name: fluentd-forward
     type: "forward"
     endpoint: splunk-fluentd-forward.offcluster.com:24224 # substitute with FQDN or IP address
     secret:
        name: secure-forward
```
+
The following sample `log-forward-instance.yaml` file uses a *secured* connection:
+
```
apiVersion: "logging.openshift.io/v1alpha1"
kind: "LogForwarding"
metadata:
  name: instance
  namespace: openshift-logging
spec:
  disableDefaultForwarding: true
  outputs:
   - name: elasticsearch
     type: "elasticsearch"
     endpoint: elasticsearch.openshift-logging.svc:9200
     secret:
        name: fluentd
   - name: fluentd-forward
     type: "forward"
     endpoint: splunk-fluentd-forward.offcluster.com:24224 # substitute with FQDN or IP address
     secret:
        name: secure-forward
  pipelines:
   - name: container-logs
     inputSource: logs.app
     outputRefs:
     - elasticsearch
     - fluentd-forward
   - name: infra-logs
     inputSource: logs.infra
     outputRefs:
     - elasticsearch
   - name: audit-logs
     inputSource: logs.audit
     outputRefs:
     - elasticsearch
```
+
* If you are using an *insecure* connection, specify the `insecure: true` configuration instead:
+
```
   - name: fluentd-forward
     type: "forward"
     endpoint: splunk-fluentd-forward.offcluster.com:24224 # substitute with FQDN or IP address
     insecure: true
```
+
The following sample `log-forward-instance.yaml` file uses an *insecure* connection:
+
```
apiVersion: "logging.openshift.io/v1alpha1"
kind: "LogForwarding"
metadata:
  name: instance
  namespace: openshift-logging
spec:
  disableDefaultForwarding: true
  outputs:
   - name: elasticsearch
     type: "elasticsearch"
     endpoint: elasticsearch.openshift-logging.svc:9200
     secret:
        name: fluentd
   - name: fluentd-forward
     type: "forward"
     endpoint: splunk-fluentd-forward.offcluster.com:24224 # substitute with FQDN or IP address
     insecure: true
  pipelines:
   - name: container-logs
     inputSource: logs.app
     outputRefs:
     - elasticsearch
     - fluentd-forward
   - name: infra-logs
     inputSource: logs.infra
     outputRefs:
     - elasticsearch
   - name: audit-logs
     inputSource: logs.audit
     outputRefs:
     - elasticsearch
```

* These sample configuration files define two outputs: `elasticsearch`, which routes to an internal Elasticsearch instance and `fluent-forward`, which routes to an instance of Fluentd. Each log type is defined under pipelines with its configured output references. For the `forward` output, substitute the `splunk-fluentd-forward.offcluster.com` value with the fully qualified domain name (FQDN) or the IP address of your external machine, as shown in the following example:
+

```
   - name: fluentd-forward
     type: "forward"
     endpoint: 1.23.456.789:24224
     secret:
        name: secure-forward
```
--
. Create the Log Forwarding API instance inside your OpenShift cluster:
+
[source]
----
[root@ocp ~]# oc create -f log-forward-instance.yaml
----
+

. **OpenShift 4.3 to 4.5 only** Annotate the ClusterLogging instance to enable the Log Forwarding API.
+
[source]
----
[root@ocp ~]# oc annotate clusterlogging -n openshift-logging instance clusterlogging.openshift.io/logforwardingtechpreview=enabled
----
+


. To check whether the logs are forwarded to the specified outputs, run the following command:
+
[source]
----
[root@ocp ~]# oc -n openshift-logging get cm fluentd -o json | jq -r '.data."fluent.conf"' > fluentd-with-logfowarding.conf
----
+
This command displays the ConfigMap configuration for Fluentd inside OpenShift. Check whether the outputs are defined inside the configuration file.

* In the following configuration file example, you can see the `elaticsearch` and `fluent-forward` outputs referenced by `@label`:
+
```
...
<label @CONTAINER_LOGS>
  <match **>
    @type copy

    <store>
      @type relabel
      @label @ELASTICSEARCH
    </store>
    <store>
      @type relabel
      @label @FLUENTD_FORWARD
    </store>
  </match>
</label>
...
```
+


== Configuring Splunk and Fluentd

When you specify the`forward` output in your `log-forward-instance.yaml` file, you can forward OpenShift logs to Splunk by using the Fluentd forward protocol. You can set up Splunk inside your OpenShift Cluster or on your external machine.

=== Setting up Splunk and Fluentd on your external machine

The following instructions explain how to manually set up Splunk and Fluentd on your external machine. If you already have Splunk deployed on your external machine, this option helps you set up the connection between your OpenShift cluster and Splunk. To receive logs from Fluentd inside your OpenShift cluster, you must deploy both Splunk and an instance of Fluentd on your machine. For the  purposes of this setup demo, Docker compose is used for installation and the external deployment of Fluentd and Splunk.


. Create the following directories to hold the necessary files:
+
[source]
----
/path/to/fluentdSplunkDir
/path/to/fluentdSplunkDir/fluentd
/path/to/fluentdSPlunkDir/fluentd/conf
/path/to/fluentdSPlunkDir/fluentd/secret
----

. Create a `Dockerfile` file under the `/path/to/fluentdSplunkDir/fluentd` directory to install essential packages while you build the Fluentd Docker image. You need to install the *build-essential* package to install all dependencies and the *fluent-plugin-splunk-enterprise* package to forward the logs to Splunk.
* Sample `Dockerfile`:
+
```
# fluentd/Dockerfile
FROM fluent/fluentd:v1.10-debian
user 0
RUN apt-get update -y
RUN apt-get install build-essential -y
RUN fluent-gem install fluent-plugin-splunk-enterprise -v 0.10.0
```
+

. [[keycert-fluentd]]*Optional:* If you are configuring a secure connection between your external Fluentd server and the Fluentd servers from your OpenShift cluster, move the  <<keycert-secret,`tls.key` and `tls.crt` files that you created earlier>> to the `/path/to/fluentdSplunkDir/secret` directory.

. Create the `docker-compose.yaml` file under the `/path/to/fluentdSplunkDir` directory for Fluentd and Splunk deployment on your external machine.
+
--
* Sample `docker-compose.yaml`:
```
version: '3'

services:
  splunk:
    hostname: splunk
    image: splunk/splunk:latest
    environment:
      SPLUNK_START_ARGS: --accept-license
      SPLUNK_ENABLE_LISTEN: 8088
      SPLUNK_PASSWORD: changeme
    ports:
      - "8000:8000"
      - "8088:8088"

  fluentd:
    build: ./fluentd
    volumes:
      - ./fluentd/conf:/fluentd/etc
      - ./fluentd/secret:/fluentd/secret # remove if not using a secured connection
    links:
      - "splunk"
    ports:
      - "24224:24224"
      - "24224:24224/udp"
```
Configure the ports for Splunk and Fluentd. You can also define a splunk password under *splunk: environment*.

--

. Create `fluent.conf` file in the `/path/to/fluentdSplunkDir/fluentd/conf/` directory to configure Fluentd.
+
--
The following `fluent.conf` file uses a *secured* connection between OpenShift Fluentd servers:
```
<source>
  @type forward
  port 24224
  <transport tls>
    cert_path /fluentd/secret/tls.crt
    private_key_path /fluentd/secret/tls.key
  </transport>
  <security>
    self_hostname fluentd
    shared_key secretpassword
  </security>
</source>

<match kubernetes.**>
  @type splunk_hec
  host splunk
  port 8088
  token 00000000-0000-0000-0000-000000000000 # substitute with token

  default_source openshift

  use_ssl true
  ssl_verify false  # skips SSL certificate verification
  #ca_file /path/to/ca.pem

  flush_interval 5s
</match>

```

* The *source* directive determines the input sources. It uses the *forward* type to accept TCP packets from your OpenShift instance.
** *port* indicates the port that the Fluentd server is listening to for data
** The *transport* section with the *tls*  parameter enables a secure TLS connection between this Fluentd server and fluentd servers in the OpenShift cluster.
*** The  *cert_path* and *private_key_path* parameters are the keys and certificates that are mounted into the Fluentd docker image.
** The *security* section is used for additional authentication
*** The *self_hostname* parameter is a required key that indicates the name of the host. This sample uses _fluentd_.
*** The *shared_key* parameter connects the Fluentd servers by using password authentication. This example uses uses _secretpassword_ as the password.
**** If you choose to use an *insecure* connection between the Fluentd servers in the OpenShift cluster and this Fluentd server, you can use the following simplified source configuration instead:
+
```
<source>
  @type forward
  port 24224
</source>
```

* The *match* directive determines the output destinations. It looks for events with matching tags and uses *splunk_hec* to send the events to Splunk by using HTTP Event Collector.
** The Splunk *host* value is required. We are using  _"splunk"_ for the host, as defined in the `docker-compose.yml`.
** The Splunk *port* value is required. We are using port `8088`, as defined in the `docker-compose.yml`.
** Replace [[fluent-conf]]*token* with the Splunk generated token. This token is obtained later in <<splunk-token,step 7>>.
** The *default_source* parameter sets the value as source metadata.
** Set the *use_ssl* parameter to true to use SSL when you connect to Splunk. By default, the Splunk deployment enables SSL for incoming HEC connections.
** The *ssl_verify* parameter is set to false to avoid SSL certificate verification. Since both the Fluentd and Splunk images are deployed on the same machine, this blog post uses an insecure connection. To secure your connection with Splunk, configure a certificate for your splunk deployment, load it into your Fluentd image, and point to it with the *ca_file* option. These steps are beyond the scope of this blog post.

See the link:https://docs.fluentd.org/input/forward[Fluentd documentation for the _forward_ input plugin] for more configuration options.

The Fluentd image that is used in this blog post has Fluent's Splunk HEC output plugin installed. See the link:https://github.com/fluent/fluent-plugin-splunk/blob/2247356927cab421af1ddb7d22bd8046726c8d62/README.hec.md[Splunk HTTP Event Collector Output Plugin documentation] for more configuration options.
--

. Deploy Splunk by running the following command:
+
[source]
----
[root@ocp ~]# docker-compose up splunk
----
+


. [[splunk-token]]Create the Splunk HTTP Event Collector data input token. Visit Splunk at `http://localhost:8000` and log in with `admin` and the password that is specified in your `docker-compose.yaml` file. Go to *Settings* > *Data Inputs* > *HTTP Event Collector* > *New Token*. Set `Name` as "openshift". In Input Settings, set `Source Type` as "Automatic" and `App Context` as "Search & Reporting (search)". Under `Index`, click `Create a new index` and set `Index Name` as "openshift".
+
image::/img/blog/splunk-index.png[Splunk Index,width=70%,align="center"]
+
Select the "openshift" index in the  Available item(s) box.
+
image::/img/blog/splunk-openshift-index.png[Splunk Openshift Index,width=70%,align="center"]
+
Leave the other fields unchanged and click *Create a new index*. Copy the generated token value to use in the <<fluent-conf, fluent.conf file>>

. Deploy Fluentd by running the following command:
+
[source]
----
[root@ocp ~]# docker-compose up fluentd
----
+


== Integrating Open Liberty JSON Logs

Since Open Liberty application pods output logs in JSON format, it is recommended to set Fluentd to parse the JSON fields from the message body. To enable JSON parsing, change the cluster logging instance's *managementState* field from *"Managed"* to *"Unmanaged"*:

```
[root@ocp ~]# oc edit ClusterLogging instance

apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"

....

spec:
  managementState: "Unmanaged"
```
*Note:* After you set this value to *"Unmanaged"*, any further changes to the _ClusterLogging_ or _LogForwarding_ instances are not automatically detected. To automatically detect changes, you must change the *managementState* field back to *"Managed"*.

Next, set the *MERGE_JSON_LOG* environment variable to *true*.

[source]
----
[root@ocp ~]# oc set env ds/fluentd MERGE_JSON_LOG=true
----

== Setting up the Splunk dashboard and viewing logs

. Go to Search & Reporting. Search for `index="openshift"` to view logs from OpenShift Container Platform.

. Download the link:https://github.com/WASdev/sample.dashboards/tree/2ef92498e507657e1e718659184f46ff4826d2ce/Liberty/OCP/Splunk%208[Sample dashboard for Liberty inside OpenShift Container Platform using Splunk 8].

. Under the Search & Reporting view, go to the _Dashboards_ tab, click `Create New Dashboard`, and give it a name, for example, `Liberty Problems Dashboard`.

. Import the downloaded sample dashboards by using the *Source* option. Using this dashboard, you can visualize message, trace, and first failure data capture (FFDC) logging data that is collected from JSON logging in Open Liberty.

image::/img/blog/splunk-dashboard.png[Splunk-Dashboard,width=70%,align="center"]

== Troubleshooting

If you find that there are no logs present on Splunk when you are done configuring, there are a few approaches to diagnose the issue.

*Connection between Fluentd and Splunk*

* Ensure that the Splunk HEC token is correct
* Check the container logs from the Fluentd instance and the Splunk instance for warnings or errors

*Connection between the OpenShift cluster and the Fluentd instance*

* Ensure that the IP/FQDN of the machine that is hosting Fluentd and Splunk is accessible from the OpenShift cluster.
* (Security) Ensure that you are using the correct key and certificates for both the OpenShift _secret_ and the Fluentd instance.
* (Security) Ensure that you are using the correct `shared_key` value for both the OpenShift _secret_ and the Fluentd instance.
* Check the logs for the Fluentd pods that are running under the `openshift-logging` namespace for warnings or errors.


== Conclusion
Application logging helps you easily retrieve and analyze problems on your servers. With the Log Forwarding API, you can use existing external enterprise log collection solutions for OpenShift logs. This post demonstrates how Splunk can help you to aggregate and analyze log events from Open Liberty servers that are running on OpenShift.
